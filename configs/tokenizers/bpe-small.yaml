tokenizer:
  vocab_size: 8192
  batch_size: 128